% Chapter Template
\chapter{Introduction} % Main chapter title
\label{INTR} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
\lhead{Chapter 1. \emph{Introduction}} 
It has become a cliche to start a discussion on the field related to classification or tagging the online multimedia information by stating just how the meteoric growth of data has been in recent decade. While it may be a very trivial and obsolete way of introducing about the online digital corpora, but it is, nonetheless, true for work in this field.\\
\hspace*{1cm}The proliferation of personalized gadgets, cheap digital cameras and any such diversification away from single use devices like mobile phones and into everything from computer web-cams to tablets, it has now become a culture of saving the every moment of our lives in digitized format. The internet services like Facebook, Flickr, Instagram etc also made it very easy for common person to share their pictures with their (online) social connections.\\
\hspace*{1cm}In present scenario, where we have proliferating robust systems effectively handling the billions of photos, images and videos; the renaissance of the 'socialization' of web activity has produced a massive amount of social interaction information. The social interaction on multimedia supporting websites have also opened a new avenue of managing this ever growing corpora of multimedia data. The point is that this social interaction data like tags, comments, likes, groups, galleries, playlists etc. all leaves some clues about the content in the question.\\
\hspace*{1cm}This social meta-data, the data related to the content, can be a pathway to manage the whole multimedia burst in proper classifications, themes  or may be ontological perspective. This meta-data can help us in many ways for example information retrieval, multimedia classification, heterogeneous learning etc. In our thesis, we are going to focus upon the images and their social meta data.\\
\hspace*{1cm}Photos are unlike the text documents have a far more immediate emotive impact - reportage from people dying in Somalia because of poverty to striking wild life photography can make an impression on viewers very quickly. In past, photographs were normally confined to an album and were rarely opened to relish the old memories. The photos were difficult to share and normally do not contain any contextual information. Where as in present scenarios, people can upload images to world wide web direct from the capture devices (like phone, tablets). They can also encode pertinent contextual information automatically and share it with all their social network contacts. This starts a cycle of interaction and annotation of that image. Over the time, the social aspect of image becomes more prevalent. This creates a need of expanding our understanding and power of utilizing this social data.\\
This thesis have focused on exploring the role; which can be played by social context information in enhancing the image classification. In image classification, an image is classified according to its visual content. For example does it contain clouds or not. We analyze some of the visual characteristics based features and then, we try to fuse these visual features with the social context information to follow a multimodal approach of classification. \\
\section{Motivation}
Image classification has many application ranging from multimedia information delivery to web search. In the past, image classification has faced two major difficulties. First, the labeled images for training are generally hard to extract out and short in supply plus labeling new images costs human labor. Secondary images can be ambiguous; e.g. an image can have multiple concepts hidden. To overcome these problems, we can leverage the other information about the images. Even when labeled data is hard to create, we can take advantage of the text data related to images or the social interaction data associated with images \cite{heterogenous}.\\
\hspace*{1cm} Apart from these problems, we also experience the problem of ambiguity of key objects in image classification. The low level features of visual information can often be ambiguous. An object can belong to more than one concepts (polysemy). In such cases, we need some help of extra data to gracefully handle such ambiguous conditions in order to get high classification accuracy.\\
\hspace*{1cm} Text and images are two distinct type of information resources and belong to two different modalities, as they present an object in different ways. However, there are some implicit connections and invariant properties, shared between images and textual information (Smeulders et al. 2000). In fact, the texts associated with images includes some form of human generated descriptions of images; thus these can be regarded as supplement to the image content.\\
\hspace*{1cm} The combination of textual information with image features has been proposed to improve the image classification results(Swain et al. 1997; Zhao \& Grosky 2002; Hu \& Bagga 2004; Song et al. 2004; Smith \& Chang 1997). \\
\hspace*{1cm} With all these cues about heterogeneous learning, we get ample motivation of taking the help of data in different modalities to have better classification of images. The unprecedented evolution of social networking gives us such data with very ease. People talk about images, puts likes, comments, tags and other different markers. These markers or rather,  we say social meta-data can be instrumental in inferring the content of images.\\
 \hspace*{1cm} Krystyna K. Matusiak has shown that how the social tagging can be a tool for enhancing the description of digital objects\cite{digiImage}. In some recent studies, it has been shown that the social-metadata can be utilize in case for better classification. (Yuan Lin and Yuqiang Chen et al \cite{heterogenous}, Lua, and Wei-Ying \cite{liu},Julian McAuley and Jure Leskovec \cite{McAuley} )\\